{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sne2114_midterm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvMPJhPv1KxQxbhgI6+/Di",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalNel97/qmss_python_midterm/blob/main/sne2114_midterm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jIXJNuMHFmH"
      },
      "source": [
        "**QMSS S5073**\n",
        "# ***Midterm***\n",
        "**Salah El-Sadek (sne2114)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eve6b5GUjFMZ"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "# Importing relevant libraries\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5fAHZlN1Pp"
      },
      "source": [
        "## **1:** \n",
        "*Import the spam dataset and print the first six rows.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHOGD1xzGdHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "57d6dacd-27ea-458b-863f-05fe32b849eb"
      },
      "source": [
        "#Reading in data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Python/Midterm/spam_dataset.csv')\n",
        "df.head(6)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make:</th>\n",
              "      <th>word_freq_address:</th>\n",
              "      <th>word_freq_all:</th>\n",
              "      <th>word_freq_3d:</th>\n",
              "      <th>word_freq_our:</th>\n",
              "      <th>word_freq_over:</th>\n",
              "      <th>word_freq_remove:</th>\n",
              "      <th>word_freq_internet:</th>\n",
              "      <th>word_freq_order:</th>\n",
              "      <th>word_freq_mail:</th>\n",
              "      <th>word_freq_receive:</th>\n",
              "      <th>word_freq_will:</th>\n",
              "      <th>word_freq_people:</th>\n",
              "      <th>word_freq_report:</th>\n",
              "      <th>word_freq_addresses:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "      <th>word_freq_business:</th>\n",
              "      <th>word_freq_email:</th>\n",
              "      <th>word_freq_you:</th>\n",
              "      <th>word_freq_credit:</th>\n",
              "      <th>word_freq_your:</th>\n",
              "      <th>word_freq_font:</th>\n",
              "      <th>word_freq_000:</th>\n",
              "      <th>word_freq_money:</th>\n",
              "      <th>word_freq_hp:</th>\n",
              "      <th>word_freq_hpl:</th>\n",
              "      <th>word_freq_george:</th>\n",
              "      <th>word_freq_650:</th>\n",
              "      <th>word_freq_lab:</th>\n",
              "      <th>word_freq_labs:</th>\n",
              "      <th>word_freq_telnet:</th>\n",
              "      <th>word_freq_857:</th>\n",
              "      <th>word_freq_data:</th>\n",
              "      <th>word_freq_415:</th>\n",
              "      <th>word_freq_85:</th>\n",
              "      <th>word_freq_technology:</th>\n",
              "      <th>word_freq_1999:</th>\n",
              "      <th>word_freq_parts:</th>\n",
              "      <th>word_freq_pm:</th>\n",
              "      <th>word_freq_direct:</th>\n",
              "      <th>word_freq_cs:</th>\n",
              "      <th>word_freq_meeting:</th>\n",
              "      <th>word_freq_original:</th>\n",
              "      <th>word_freq_project:</th>\n",
              "      <th>word_freq_re:</th>\n",
              "      <th>word_freq_edu:</th>\n",
              "      <th>word_freq_table:</th>\n",
              "      <th>word_freq_conference:</th>\n",
              "      <th>char_freq_;:</th>\n",
              "      <th>char_freq_(:</th>\n",
              "      <th>char_freq_[:</th>\n",
              "      <th>char_freq_!:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>char_freq_#:</th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>capital_run_length_longest:</th>\n",
              "      <th>capital_run_length_total:</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make:  word_freq_address:  ...  capital_run_length_total:  spam\n",
              "0             0.00                0.64  ...                        278     1\n",
              "1             0.21                0.28  ...                       1028     1\n",
              "2             0.06                0.00  ...                       2259     1\n",
              "3             0.00                0.00  ...                        191     1\n",
              "4             0.00                0.00  ...                        191     1\n",
              "5             0.00                0.00  ...                         54     1\n",
              "\n",
              "[6 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1IliMNvHJxA"
      },
      "source": [
        "## **2:**\n",
        "*Read through the documentation of the original dataset here:*\n",
        "\n",
        "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\n",
        "\n",
        "*The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buyoYdEkIa7s"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**The 3 variables I chose were 'capital_run_length_total', 'char_freq_$', and 'word_freq_free'. These variables were chosen with the idea being to develop a model that is able to identify spam emails in general, and not just spam for personalized emails in question (given that our source of non-spam emails were emails of HP employees). For this reason, variables that are generally used to identify spam were chosen, while variables counting the frequency of HP specific terms (george, 650 for area code, meeting, conference, hp, hpl, etc.) were avoided as they would not generalize well for developing a spam filter for the average email user.**\n",
        "\n",
        "**Spam emails often contain heavily capitalized words to grab attention from among the multitude of other emails a user gets, spam or otherwise. So having a measure of the average length of consecutive capital letter sequences (capital_run_length_total) is a good differentiator between spam and non-spam email. Moreover, overuse of the dollar sign character '$' and repeat emphasize on free things is a hallmark of money scheme spam emails or dubious advertisements.**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1FGrPXjkC4z"
      },
      "source": [
        "## **3:**\n",
        "*Visualize the univariate distribution of each of the variables in the previous question.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "s1418-l-HXw5",
        "outputId": "d070b181-cc36-4a28-c17b-99b0e3260c71"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Spam Histogram\n",
        "plt.hist(data = df, x = 'spam')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Spam')"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Spam')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "B_84PVlSnX8U",
        "outputId": "c9982469-3b4c-4889-8a6d-482a3ef963a0"
      },
      "source": [
        "# Average length of sequence of consecutive capital letters in email histogram\n",
        "sns.catplot(x = 'spam', y = 'capital_run_length_average:', kind = \"box\", data = df)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c84332510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Ve90vPnjnbfK",
        "outputId": "2b4fcf2e-ff5c-432e-a3ae-496d547a00e4"
      },
      "source": [
        "# Proportion of characters in email being \"$\" histogram\n",
        "sns.catplot(x = 'spam', y = 'char_freq_$:', kind = \"box\", data = df)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c83d50290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "FZvSxuwinc_U",
        "outputId": "fd16ec02-90ec-4d53-83a8-48f4d73d4d8e"
      },
      "source": [
        "# Proportion of words in email being \"free\" histogram\n",
        "sns.catplot(x = 'spam', y = 'word_freq_free:', kind = \"box\", data = df)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c83e2c5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUQDezyspAWU"
      },
      "source": [
        "## **4:**\n",
        "*Name each of the supervised learning models that we have learned thus far that are used to predict dependent variables like \"spam\".*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OGWJJstDEm0"
      },
      "source": [
        "---\n",
        "\n",
        "**Penalized Logistic Regression (L1 & L2), Unpenalized Logistic Regression, KNN Classification, Support Vector Machines/Classifier (SVM/C) Models, Decision Tree Classifier Models, and Ensemble Decision Tree Classifier Models such as Random Forest Classifier Models or Bootstrap aggregation 'bagging' Models.**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihTFXbCDEkvc"
      },
      "source": [
        "## **5:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCwYervwEoeQ"
      },
      "source": [
        "*Describe the importance of training and test data.  Why do we separate data into these subsets?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skcpTjVCEslQ"
      },
      "source": [
        "---\n",
        "\n",
        "**We separate our data into test and training data as to be able to test our model in question using a subset of data ('test' subset) that is different than the data the model was initially trained on (the 'train' subset). This is done to get an accurate assessment of whether our model is effective at predicting unseen data or not.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouFrwZHPEtmm"
      },
      "source": [
        "##**6:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bYBzmU8E25X"
      },
      "source": [
        "*What is k-fold cross validation and what do we use it for?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0gIsst9E4K5"
      },
      "source": [
        "---\n",
        "\n",
        "**K-fold cross validation refers to a kind of multi-sampling procedure where a sample dataset is randomly divided into k number of groups where one group is assigned as the 'test' subset and the rest of the groups (k-1) are assigned as 'training' subsets. Our model is trained using these k-1 training data and then evaluated using the 'test' data.**\n",
        "\n",
        "**This procedure of picking which pre-assigned k-groups are 'test' or 'train' subsets, as well as the training and testing of our model using them, is run k number of times (splits) so that each k-fold group gets to act as the 'test' subset for our model once, and act to 'train' our model k-1 number of times. It is important to note that the initial random assignment of observations into k-groups is done only once at the beginning to maintain each observation in the data acting as 'test' once and 'train' k-1 times. (Note: splits here refers to the number of iterations within one cross-validation run, and not the number of repeats used in repeat cross-validation).**\n",
        "\n",
        "**K-fold cross validation is preferred to a one-off test-train split evaluation of our model since it allows us to get multiple unique evaluations of how \"objective\" (closer to the truth) our model predictions are, without needing extra sample datasets than the one you have.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64wVTG-iFCsw"
      },
      "source": [
        "##**7:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY826UJiFGxw"
      },
      "source": [
        "*How is k-fold cross validation different from stratified k-fold cross validation?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAuU5qgeFIDB"
      },
      "source": [
        "---\n",
        "\n",
        "**When k-fold cross-validation shuffles and randomly assigns observations to k-fold groups, it gives each observation a uniform probablity of being put into one of the k-groups. But given an outcome with multiple categories, this uniform probability assignment might lead to k-fold groups that are biased, with outcome category distributions that are different than the distribution of outcome categories in our original, full dataset.**\n",
        "\n",
        "**Stratified k-fold cross-validation fixes this issue by insuring our k-fold groups match our original dataset in terms of outcome proportions. It assigns observations to k-groups not using a unform probability distribution, but the actual distribution of outcome categories in our dataset.**\n",
        "\n",
        "**This is especially important if our outcomes are relatively skewed towards being in one or more category. Meaning if we uniformly assign these observations into k-groups, some of those groups might end up having little to no representation of one of the outcome categories and our model would then be inaccurately trained and evaluated.** \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfpsj2vFSyZ"
      },
      "source": [
        "##**8:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebq6YPs3FUw4"
      },
      "source": [
        "*Choose one model from question four.  Split the data into training and test subsets.  Build a model with the three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "p9I02cs-Elk9",
        "outputId": "dd714baa-0c9b-4ad3-ac86-2539bc01d32b"
      },
      "source": [
        "df_3v = df.loc[:, ['capital_run_length_average:', 'char_freq_$:', 'word_freq_free:', 'spam']]\n",
        "df_3v.head()"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.756</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.114</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.821</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   capital_run_length_average:  char_freq_$:  word_freq_free:  spam\n",
              "0                        3.756         0.000             0.32     1\n",
              "1                        5.114         0.180             0.14     1\n",
              "2                        9.821         0.184             0.06     1\n",
              "3                        3.537         0.000             0.31     1\n",
              "4                        3.537         0.000             0.31     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sru9Oif7I6_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "9d59ae70-b1fa-4457-88c7-79d6d043e21d"
      },
      "source": [
        "y1 = df_3v['spam']\n",
        "X1 = df_3v.loc[:, df_3v.columns != 'spam']\n",
        "\n",
        "print(y1[0:5])\n",
        "X1.head()"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: spam, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.756</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.114</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.821</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   capital_run_length_average:  char_freq_$:  word_freq_free:\n",
              "0                        3.756         0.000             0.32\n",
              "1                        5.114         0.180             0.14\n",
              "2                        9.821         0.184             0.06\n",
              "3                        3.537         0.000             0.31\n",
              "4                        3.537         0.000             0.31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrqR4SkGJtyg"
      },
      "source": [
        "**Train-test splitting our data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDSzkv01JmWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e8b476ec-738e-4d24-99c8-86a673fcfb43"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=0)\n",
        "\n",
        "print(y1_train[0:5])\n",
        "X1_train.head()"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118     1\n",
            "261     1\n",
            "598     1\n",
            "1770    1\n",
            "905     1\n",
            "Name: spam, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>102.666</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>5.423</td>\n",
              "      <td>0.707</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>2.551</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1770</th>\n",
              "      <td>5.210</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>2.441</td>\n",
              "      <td>0.433</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      capital_run_length_average:  char_freq_$:  word_freq_free:\n",
              "118                       102.666         0.000             0.00\n",
              "261                         5.423         0.707             1.11\n",
              "598                         2.551         0.000             0.00\n",
              "1770                        5.210         0.000             3.26\n",
              "905                         2.441         0.433             0.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrEzhMzYikH5"
      },
      "source": [
        "####**KNN Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLmo9FiJFWvL"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCnZo0qKZV7M",
        "outputId": "709d333a-e15d-47f9-c044-f06e618d798f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# To tune the parameter defining number of k neighbors\n",
        "knn1_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "p_grid_knn1 = {'kneighborsclassifier__n_neighbors': [1,3,5,7,9,11,13,15]}\n",
        "\n",
        "grid_knn1 = GridSearchCV(knn1_pipe, p_grid_knn1, cv=10)\n",
        "grid_knn1.fit(X1_train, y1_train)\n",
        "\n",
        "print(\"KNN Classifier (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn1.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_knn1.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_knn1.score(X1_test, y1_test)))"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN Classifier (Scaled)\n",
            "best mean cross-validation score: 0.850\n",
            "best parameters: {'kneighborsclassifier__n_neighbors': 7}\n",
            "test-set score: 0.844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDLT9ZTOFh45"
      },
      "source": [
        "##**9:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoPPJh-rFh46"
      },
      "source": [
        "*Choose a second model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous model?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtuDypyOiupG"
      },
      "source": [
        "####**Penalized (L2) Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psImMYMCFjm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d7253f-7e67-4476-ff02-e63448262bbb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "plog_pipe = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2'))\n",
        "\n",
        "# Tuning for the C parameter in the Ridge L2 penalty logistic regression\n",
        "p_grid_plog = {'logisticregression__C': [0.1, 1, 10, 100, 1000, 10000]}\n",
        "\n",
        "grid_plog = GridSearchCV(plog_pipe, p_grid_plog, cv=10)\n",
        "grid_plog.fit(X1_train, y1_train)\n",
        "\n",
        "print(\"L2 Penalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_plog.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_plog.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_plog.score(X1_test, y1_test)))"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 Penalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "best parameters: {'logisticregression__C': 100}\n",
            "test-set score: 0.822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN-QF5w4FjGz"
      },
      "source": [
        "##**10:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev8rKREfFjG0"
      },
      "source": [
        "*Choose a third model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3mQPNL5jmai"
      },
      "source": [
        "####**Unpenalized Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBJ2bftjmar",
        "outputId": "202e11e7-8473-445f-ac19-16f92a492cc4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scaler = StandardScaler().fit(X1_train)\n",
        "X1_train_scaled = scaler.transform(X1_train)\n",
        "X1_test_scaled = scaler.transform(X1_test)\n",
        "\n",
        "ulog = LogisticRegression(penalty='none')\n",
        "ulog.fit(X1_train_scaled, y1_train)\n",
        "\n",
        "print(\"Unpenalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(cross_val_score(ulog, X1_train_scaled, y1_train, cv=10, scoring='accuracy').mean()))\n",
        "print(\"test-set score: {:.3f}\".format(ulog.score(X1_test_scaled, y1_test)))\n",
        "\n",
        "# No parameters to tune in unpenalized logistic regression"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpenalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "test-set score: 0.822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO4dn_kFF5iY"
      },
      "source": [
        "##**11:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkGca58AF5i3"
      },
      "source": [
        "*Choose a fourth model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i858hwaOiqAj"
      },
      "source": [
        "####**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3JMyvEHFivf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3863b02f-6a72-418e-8c27-44db11223759"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "scaler = StandardScaler().fit(X1_train)\n",
        "X1_train_scaled = scaler.transform(X1_train)\n",
        "X1_test_scaled = scaler.transform(X1_test)\n",
        "\n",
        "# Used max_features = sqrt(total # of predictors/features) = sqrt(3)~2\n",
        "for_mod = RandomForestClassifier(n_estimators = 200, max_features = 2)\n",
        "\n",
        "# Tuning for number of trees to evaluate\n",
        "p_grid_for = {'n_estimators': [100, 200, 300, 400, 500]}\n",
        "\n",
        "grid_for = GridSearchCV(for_mod, p_grid_for, cv=10)\n",
        "grid_for.fit(X1_train_scaled, y1_train)\n",
        "\n",
        "print(\"Random Forest Classifier Model (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_for.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_for.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_for.score(X1_test_scaled, y1_test)))"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Model (Scaled)\n",
            "best mean cross-validation score: 0.838\n",
            "best parameters: {'n_estimators': 500}\n",
            "test-set score: 0.831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQIc9R_CmAw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fda20bf-1da4-4b44-de0a-6b0d28db0538"
      },
      "source": [
        "print(\"With 3 variables\")\n",
        "print(\" \")\n",
        "print(\"KNN Classifier (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn1.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_knn1.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"L2 Penalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_plog.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_plog.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"Unpenalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_ulog.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_ulog.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"Random Forest Classifier Model (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_for.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_for.score(X1_test_scaled, y1_test)))"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 3 variables\n",
            " \n",
            "KNN Classifier (Scaled)\n",
            "best mean cross-validation score: 0.850\n",
            "test-set score: 0.844\n",
            " \n",
            "L2 Penalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "test-set score: 0.822\n",
            " \n",
            "Unpenalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "test-set score: 0.822\n",
            " \n",
            "Random Forest Classifier Model (Scaled)\n",
            "best mean cross-validation score: 0.838\n",
            "test-set score: 0.831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HxTfDVj35Zh"
      },
      "source": [
        "---\n",
        "**We see that using only our 3 chosen variables in our model, KNN Classification seems to have the best CV and test-data prediction scores, followed by Random Forest Classification, and then both penalized and unpenalized logistic regression. Both types of logistic regression models gave identical scores.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD5RulU3GC_N"
      },
      "source": [
        "##**12:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1NBwIsgGE0y"
      },
      "source": [
        "*Now rerun your best model from questions 8 through 11, but this time add three new variables to the model that you think will increase prediction accuracy.   Did this model predict test data better than your previous models?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UINKFF-VGG4W"
      },
      "source": [
        "---\n",
        "\n",
        "**The 3 extra variables I chose were 'char_freq_!', 'word_freq_credit', and 'word_freq_000'.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn3OxZvJpbdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "c942f7b8-d357-44d5-d16d-179f99f61d10"
      },
      "source": [
        "# Proportion of characters in email being \"!\" histogram\n",
        "sns.catplot(x = 'spam', y = 'char_freq_!:', kind = \"box\", data = df)"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c83c5e6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aReQKMNp7WC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "02beede6-d730-41e4-e247-2190431ebdda"
      },
      "source": [
        "# Proportion of words in email being \"credit\" histogram\n",
        "sns.catplot(x = 'spam', y = 'word_freq_credit:', kind = \"box\", data = df)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c83bbe3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPYKnVB2qCXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "a24b4eb9-e7b7-483b-b380-afac6bb4760e"
      },
      "source": [
        "# Proportion of words in email being \"000\" histogram\n",
        "sns.catplot(x = 'spam', y = 'word_freq_000:', kind = \"box\", data = df)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7c83b6fb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5XHxY2rrZpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "73c93f01-81af-41f1-81a8-4532f7e90252"
      },
      "source": [
        "df_6v = df.loc[:, ['capital_run_length_average:', 'char_freq_$:', 'word_freq_free:', 'char_freq_!:', 'word_freq_credit:', 'word_freq_000:', 'spam']]\n",
        "df_6v.head()"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "      <th>char_freq_!:</th>\n",
              "      <th>word_freq_credit:</th>\n",
              "      <th>word_freq_000:</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.756</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.114</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.821</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   capital_run_length_average:  char_freq_$:  ...  word_freq_000:  spam\n",
              "0                        3.756         0.000  ...            0.00     1\n",
              "1                        5.114         0.180  ...            0.43     1\n",
              "2                        9.821         0.184  ...            1.16     1\n",
              "3                        3.537         0.000  ...            0.00     1\n",
              "4                        3.537         0.000  ...            0.00     1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFqKCMEUGHP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5236e103-903c-4539-e901-3dd701ea7231"
      },
      "source": [
        "y2 = df_6v['spam']\n",
        "X2 = df_6v.loc[:, df_6v.columns != 'spam']\n",
        "\n",
        "print(y2[0:5])\n",
        "X2.head()"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: spam, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "      <th>char_freq_!:</th>\n",
              "      <th>word_freq_credit:</th>\n",
              "      <th>word_freq_000:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.756</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.114</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.821</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.537</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   capital_run_length_average:  char_freq_$:  ...  word_freq_credit:  word_freq_000:\n",
              "0                        3.756         0.000  ...               0.00            0.00\n",
              "1                        5.114         0.180  ...               0.00            0.43\n",
              "2                        9.821         0.184  ...               0.32            1.16\n",
              "3                        3.537         0.000  ...               0.00            0.00\n",
              "4                        3.537         0.000  ...               0.00            0.00\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3MxJyGnnYmH"
      },
      "source": [
        "**Train-test splitting our data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2vckA0QnYmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4886a42a-4593-4b0e-bbaa-208817bcafb7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=0)\n",
        "\n",
        "print(y2_train[0:5])\n",
        "X2_train.head()"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118     1\n",
            "261     1\n",
            "598     1\n",
            "1770    1\n",
            "905     1\n",
            "Name: spam, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>word_freq_free:</th>\n",
              "      <th>char_freq_!:</th>\n",
              "      <th>word_freq_credit:</th>\n",
              "      <th>word_freq_000:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>102.666</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.542</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>5.423</td>\n",
              "      <td>0.707</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>2.551</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1770</th>\n",
              "      <td>5.210</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.26</td>\n",
              "      <td>2.152</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>2.441</td>\n",
              "      <td>0.433</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.433</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      capital_run_length_average:  ...  word_freq_000:\n",
              "118                       102.666  ...            0.00\n",
              "261                         5.423  ...            0.00\n",
              "598                         2.551  ...            0.00\n",
              "1770                        5.210  ...            0.00\n",
              "905                         2.441  ...            0.76\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33FVl97wiD8i"
      },
      "source": [
        "###**KNN Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0a55qOseZRt"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpcwTvJieZR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467cfae4-36f0-4406-8945-f7c74f7171ef"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# To tune the parameter defining number of k neighbors\n",
        "knn2_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "p_grid_knn2 = {'kneighborsclassifier__n_neighbors': [1,3,5,7,9,11,13,15]}\n",
        "\n",
        "grid_knn2 = GridSearchCV(knn2_pipe, p_grid_knn2, cv=10)\n",
        "grid_knn2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"KNN Classifier (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn2.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_knn2.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_knn2.score(X2_test, y2_test)))"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN Classifier (Scaled)\n",
            "best mean cross-validation score: 0.881\n",
            "best parameters: {'kneighborsclassifier__n_neighbors': 9}\n",
            "test-set score: 0.874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0dfqyUM4wil"
      },
      "source": [
        "---\n",
        "**Yes, the KNN Classification model with 6 predictors had better CV and test-data prediction scores than all the previous models that were run with only 3 variables.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRumxQ1dGQB3"
      },
      "source": [
        "##**13:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTObUJKcGSOx"
      },
      "source": [
        "*Rerun all your other models with this final set of six variables, evaluate prediction error, and choose a final model.  Why did you select this model among all of the models that you ran?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVY3Ws9nzXF"
      },
      "source": [
        "####**Penalized (L2) Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gEe0kb0nzXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635f085c-0b65-4f14-968f-e9e6706aed14"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "plog_pipe2 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2'))\n",
        "\n",
        "# Tuning for the C parameter in the Ridge L2 penalty logistic regression\n",
        "p_grid_plog2 = {'logisticregression__C': [0.1, 1, 10, 100, 1000, 10000]}\n",
        "\n",
        "grid_plog2 = GridSearchCV(plog_pipe2, p_grid_plog2, cv=10)\n",
        "grid_plog2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"L2 Penalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_plog2.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_plog2.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_plog2.score(X2_test, y2_test)))"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 Penalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.839\n",
            "best parameters: {'logisticregression__C': 100}\n",
            "test-set score: 0.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BNk_vuwnzXI"
      },
      "source": [
        "####**Unpenalized Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKGlrbSfnzXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b9244f-520f-4a52-9b8d-37e7fa9df357"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scaler = StandardScaler().fit(X2_train)\n",
        "X2_train_scaled = scaler.transform(X2_train)\n",
        "X2_test_scaled = scaler.transform(X2_test)\n",
        "\n",
        "ulog2 = LogisticRegression(penalty='none')\n",
        "ulog2.fit(X2_train_scaled, y2_train)\n",
        "\n",
        "print(\"Unpenalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(cross_val_score(ulog2, X2_train_scaled, y2_train, cv=10, scoring='accuracy').mean()))\n",
        "print(\"test-set score: {:.3f}\".format(ulog2.score(X2_test_scaled, y2_test)))\n",
        "\n",
        "# No parameters to tune in unpenalized logistic regression"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpenalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.839\n",
            "test-set score: 0.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CXLskhnzXJ"
      },
      "source": [
        "####**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eoj_D5r4nzXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f4b414-a8ef-42c0-8ceb-fc76693355e0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "scaler = StandardScaler().fit(X2_train)\n",
        "X2_train_scaled = scaler.transform(X2_train)\n",
        "X2_test_scaled = scaler.transform(X2_test)\n",
        "\n",
        "# Used max_features = sqrt(total # of predictors/features) = sqrt(6)~3\n",
        "for_mod2 = RandomForestClassifier(n_estimators = 200, max_features = 3)\n",
        "\n",
        "# Tuning for number of trees to evaluate\n",
        "p_grid_for2 = {'n_estimators': [100, 200, 300, 500, 600]}\n",
        "\n",
        "grid_for2 = GridSearchCV(for_mod2, p_grid_for2, cv=10)\n",
        "grid_for2.fit(X2_train_scaled, y2_train)\n",
        "\n",
        "print(\"Random Forest Classifier Model (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_for2.best_score_))\n",
        "print(\"best parameters: {}\".format(grid_for2.best_params_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_for2.score(X2_test_scaled, y2_test)))"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Model (Scaled)\n",
            "best mean cross-validation score: 0.881\n",
            "best parameters: {'n_estimators': 100}\n",
            "test-set score: 0.893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CxjRGwnzXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56671c6e-0d50-4d39-8aa0-db3c0d6d261a"
      },
      "source": [
        "print(\"With 6 variables\")\n",
        "print(\" \")\n",
        "print(\"KNN Classifier (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn2.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_knn2.score(X2_test, y2_test)))\n",
        "print(\" \")\n",
        "print(\"L2 Penalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_plog2.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_plog2.score(X2_test, y2_test)))\n",
        "print(\" \")\n",
        "print(\"Unpenalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_ulog2.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_ulog2.score(X2_test, y2_test)))\n",
        "print(\" \")\n",
        "print(\"Random Forest Classifier Model (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_for2.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_for2.score(X2_test_scaled, y2_test)))\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"With 3 variables\")\n",
        "print(\" \")\n",
        "print(\"KNN Classifier (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn1.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_knn1.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"L2 Penalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_plog.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_plog.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"Unpenalized Logistic Regression (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_ulog.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_ulog.score(X1_test, y1_test)))\n",
        "print(\" \")\n",
        "print(\"Random Forest Classifier Model (Scaled)\")\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(grid_for.best_score_))\n",
        "print(\"test-set score: {:.3f}\".format(grid_for.score(X1_test_scaled, y1_test)))"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 6 variables\n",
            " \n",
            "KNN Classifier (Scaled)\n",
            "best mean cross-validation score: 0.881\n",
            "test-set score: 0.874\n",
            " \n",
            "L2 Penalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.839\n",
            "test-set score: 0.834\n",
            " \n",
            "Unpenalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.839\n",
            "test-set score: 0.834\n",
            " \n",
            "Random Forest Classifier Model (Scaled)\n",
            "best mean cross-validation score: 0.881\n",
            "test-set score: 0.893\n",
            " \n",
            " \n",
            "With 3 variables\n",
            " \n",
            "KNN Classifier (Scaled)\n",
            "best mean cross-validation score: 0.850\n",
            "test-set score: 0.844\n",
            " \n",
            "L2 Penalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "test-set score: 0.822\n",
            " \n",
            "Unpenalized Logistic Regression (Scaled)\n",
            "best mean cross-validation score: 0.825\n",
            "test-set score: 0.822\n",
            " \n",
            "Random Forest Classifier Model (Scaled)\n",
            "best mean cross-validation score: 0.838\n",
            "test-set score: 0.831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Oc5JZA2guv"
      },
      "source": [
        "---\n",
        "**Now that we added 3 more variables to our initial 3 for a total of 6 predictor variables, we see that the Random Forest Classification and KNN Classification had the same CV prediction scores, but the Random Forest Classification model had a higher test-data prediction score. So for this reason, we will choose the Random Forest Classification model with 6 predictor variables as our final model.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE1QKmiTGXjJ"
      },
      "source": [
        "##**14:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P66TfIUGdj-"
      },
      "source": [
        "*What variable that currently is not in your model, if included, would be likely to increase your final model's predictive power?  For this answer try to speculate about a variable outside the variables available in the data that would improve you model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnshUwU3WsTp"
      },
      "source": [
        "**A variable which counts the frequency of the word 'click' (word_freq_click) in an email. This is because 'click' is not an overused word in personal or professional email, but ubiquitous in spam email and ads of most kinds (given that the primary purpose of a spam email is to get the user click links to external, unverified websites.**\n",
        "\n",
        "**I think this variable would be effective in improving the predictive power of our model given that it is sensitive enough applicable to many kinds of spam emails (money schemes, advertisements, etc.), while being uncommon enough in traditional email settings as to have a low risk of incorrectly labeling email as spam when it is not.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yckVZpbRUy6"
      },
      "source": [
        "##**15:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZKbCTUZRZNj"
      },
      "source": [
        "*Lastly, you have listed each of the models that we have learned to use to predict dependent variables like spam.  List each model we have focused on in class thus far that you could use to evaluate data with a continuous dependent variable.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8GwL2kyRb95"
      },
      "source": [
        "**KNN Regression, Ridge Regresssion, Lasso Regression, Ordinary Least Squares (OLS) Regression, Bagging (bootstrap aggregation) Regression, and Random Forest Regression.**"
      ]
    }
  ]
}